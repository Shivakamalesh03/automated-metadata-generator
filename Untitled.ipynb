{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef844468-2712-4336-ac9a-51ed0b5415a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import pytesseract\n",
    "import docx\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from datetime import datetime\n",
    "import langdetect\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import uuid\n",
    "import spacy\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9947c6c4-cad5-49a5-9c78-b2548386f881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Load NLP models\n",
    "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# --- Text Extraction Functions ---\n",
    "def extract_text_from_txt(file):\n",
    "    return file.read().decode(\"utf-8\")\n",
    "\n",
    "def extract_text_from_docx(file):\n",
    "    doc = docx.Document(file)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "def extract_text_from_pdf(file):\n",
    "    text = \"\"\n",
    "    doc = fitz.open(stream=file.read(), filetype=\"pdf\")\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def extract_text_from_scanned_pdf(file_path):\n",
    "    images = convert_from_path(file_path)\n",
    "    text = \"\"\n",
    "    for image in images:\n",
    "        text += pytesseract.image_to_string(image)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e13753e-c63f-49d1-9a47-e83c6c29e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Metadata Generation Function ---\n",
    "def generate_metadata(text, filename, filetype, page_count=None):\n",
    "    words = text.split()\n",
    "    lines = text.strip().split(\"\\n\")\n",
    "\n",
    "    title = next((line.strip() for line in lines if len(line.strip()) > 10), filename)\n",
    "    if len(title) > 80:\n",
    "        title = title[:77] + \"...\"\n",
    "\n",
    "    try:\n",
    "        summary = summarizer(text[:1000], max_length=100, min_length=30, do_sample=False)[0]['summary_text']\n",
    "    except:\n",
    "        summary = \" \".join(words[:40]) + (\"...\" if len(words) > 40 else \"\")\n",
    "\n",
    "    cleaned_words = [word.lower().strip(\".,()[]{}\\\":'\") for word in words if len(word) > 4 and word.lower() not in ENGLISH_STOP_WORDS]\n",
    "    freq_keywords = [word for word, count in Counter(cleaned_words).most_common(15)]\n",
    "    keywords = list(dict.fromkeys(freq_keywords))[:10]\n",
    "\n",
    "    try:\n",
    "        language = langdetect.detect(text[:1000])\n",
    "    except:\n",
    "        language = \"unknown\"\n",
    "\n",
    "    doc = nlp(text[:1000])\n",
    "    named_entities = list(set([ent.text for ent in doc.ents if len(ent.text) > 4]))[:10]\n",
    "\n",
    "    metadata = {\n",
    "        \"document_id\": str(uuid.uuid4()),\n",
    "        \"title\": title,\n",
    "        \"summary\": summary.strip(),\n",
    "        \"keywords\": keywords,\n",
    "        \"file_type\": filetype,\n",
    "        \"character_count\": len(text),\n",
    "        \"word_count\": len(words),\n",
    "        \"uploaded_on\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"filename\": filename,\n",
    "        \"language\": language,\n",
    "        \"named_entities\": named_entities\n",
    "    }\n",
    "\n",
    "    if page_count:\n",
    "        metadata[\"page_count\"] = page_count\n",
    "\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b828642b-86db-4c48-878b-50ef027a22f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"document_id\": \"9d885713-0653-4ac6-af50-5435378c3abf\",\n",
      "  \"title\": \"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lo...\",\n",
      "  \"summary\": \"Lorem Ipsum has been  the industry's standard dummy text ever since the 1500s . It has survived not only five centuries, but also the leap into electronic typesetting . Popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages .\",\n",
      "  \"keywords\": [\n",
      "    \"lorem\",\n",
      "    \"ipsum\",\n",
      "    \"dummy\",\n",
      "    \"typesetting\",\n",
      "    \"simply\",\n",
      "    \"printing\",\n",
      "    \"industry\",\n",
      "    \"industry's\",\n",
      "    \"standard\",\n",
      "    \"1500s\"\n",
      "  ],\n",
      "  \"file_type\": \"pdf\",\n",
      "  \"character_count\": 3498,\n",
      "  \"word_count\": 546,\n",
      "  \"uploaded_on\": \"2025-06-22 12:17:53\",\n",
      "  \"filename\": \"sample-pdf-file.pdf\",\n",
      "  \"language\": \"en\",\n",
      "  \"named_entities\": [\n",
      "    \"the 1500s\",\n",
      "    \"the \\n1960s\",\n",
      "    \"Lorem Ipsum\",\n",
      "    \"five centuries\",\n",
      "    \"Aldus PageMaker\",\n",
      "    \"Letraset\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Sample testing code (for local use only)\n",
    "    filepath = r\"C:\\Users\\SHIVA KAMALESH\\Downloads\\sample-pdf-file.pdf\"\n",
    "\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        try:\n",
    "            text = extract_text_from_pdf(f)\n",
    "        except:\n",
    "            text = extract_text_from_scanned_pdf(filepath)\n",
    "\n",
    "        metadata = generate_metadata(text, os.path.basename(filepath), \"pdf\")\n",
    "        print(json.dumps(metadata, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6794f-38bd-4059-a676-3da91db2eb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
