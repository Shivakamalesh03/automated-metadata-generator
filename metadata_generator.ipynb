{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa58f181-d7f8-4ff7-810e-3762f37a4b8d",
   "metadata": {},
   "source": [
    "**Automated Metadata Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e07cc36-4871-47d5-a3d7-4d61810e4534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 11.4 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 8.7 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.2/12.8 MB 7.9 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.7/12.8 MB 6.5 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 5.4 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.3/12.8 MB 5.1 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.8/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.9/12.8 MB 4.7 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.4/12.8 MB 4.6 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.7/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.5/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 3.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 3.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 3.6 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Install all required packages\n",
    "!pip install spacy torch transformers langdetect pdf2image pytesseract python-docx pymupdf -q\n",
    "\n",
    "# Download the spaCy English model\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "637fe745-3172-45ae-bd41-9cc95ecd9825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This project extracts and generates structured metadata from uploaded documents (PDF, DOCX, TXT) using NLP and OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2c7831e-f091-40c9-8d2e-782a7aef6617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pytesseract\n",
    "import docx\n",
    "import fitz #pyMupdf\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from datetime import datetime\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac424935-f6a7-4986-9792-82a6d6d0f649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd3f67db-c5ef-4fe4-980d-26c797f20f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import langdetect\n",
    "import uuid\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def generate_metadata(text, filename, filetype, page_count=None):\n",
    "    words = text.split()\n",
    "    lines = text.strip().split(\"\\n\")\n",
    "\n",
    "    title = next((line.strip() for line in lines if len(line.strip()) > 10), filename)\n",
    "    if len(title) > 80:\n",
    "        title = title[:77] + \"...\"\n",
    "\n",
    "    try:\n",
    "        summary = summarizer(text[:1000], max_length=100, min_length=30, do_sample=False)[0]['summary_text']\n",
    "    except:\n",
    "        summary = \" \".join(words[:40]) + (\"...\" if len(words) > 40 else \"\")\n",
    "    summary = summary.strip()\n",
    "\n",
    "    cleaned_words = [word.lower().strip(\".,()[]{}\\\":'\") for word in words if len(word) > 4 and word.lower() not in ENGLISH_STOP_WORDS]\n",
    "    freq_keywords = [word for word, count in Counter(cleaned_words).most_common(15)]\n",
    "    keywords = list(dict.fromkeys(freq_keywords))[:10]\n",
    "\n",
    "    try:\n",
    "        language = langdetect.detect(text[:1000])\n",
    "    except:\n",
    "        language = \"unknown\"\n",
    "\n",
    "    doc = nlp(text[:1000])\n",
    "    named_entities = list(set([ent.text for ent in doc.ents if len(ent.text.strip()) > 3]))\n",
    "\n",
    "    document_id = str(uuid.uuid4())\n",
    "\n",
    "    metadata = {\n",
    "        \"document_id\": document_id,\n",
    "        \"title\": title,\n",
    "        \"summary\": summary,\n",
    "        \"keywords\": keywords,\n",
    "        \"file_type\": filetype,\n",
    "        \"character_count\": len(text),\n",
    "        \"word_count\": len(words),\n",
    "        \"uploaded_on\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"filename\": filename,\n",
    "        \"language\": language,\n",
    "        \"named_entities\": named_entities\n",
    "    }\n",
    "\n",
    "    if page_count:\n",
    "        metadata[\"page_count\"] = page_count\n",
    "\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b1292e0-fa0f-4570-83cb-d4a5383e7fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r\"C:\\Users\\SHIVA KAMALESH\\Desktop\\Finclub Summer Project 2 (2025)[1].docx\" # <-- update your file here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a5db8fe-91f8-494e-be91-a3fff34321f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetype = filepath.split(\".\")[-1].lower()\n",
    "\n",
    "if filetype == \"txt\":\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        text = extract_text_from_txt(f)\n",
    "\n",
    "elif filetype == \"docx\":\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        text = extract_text_from_docx(f)\n",
    "\n",
    "elif filetype == \"pdf\":\n",
    "    try:\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            text = extract_text_from_pdf(f)\n",
    "    except:\n",
    "        text = extract_text_from_scanned_pdf(filepath)\n",
    "\n",
    "else:\n",
    "    print(\"❌ Unsupported file type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "970181c8-c6ed-4321-9374-c653bbd02906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"document_id\": \"8af61fca-ffbd-41c0-bc46-abd7a53e6319\",\n",
      "  \"title\": \"Finance Club\",\n",
      "  \"summary\": \"Bank A aims to improve its credit risk management framework by developing a forward-looking Behaviour Score . The goal is to build a model that can accurately flag potential defaulters in advance, allowing the bank to adjust credit exposure and trigger early warning systems .\",\n",
      "  \"keywords\": [\n",
      "    \"credit\",\n",
      "    \"model\",\n",
      "    \"default\",\n",
      "    \"payment\",\n",
      "    \"classification\",\n",
      "    \"month\",\n",
      "    \"customer\",\n",
      "    \"e.g\",\n",
      "    \"financial\",\n",
      "    \"evaluation\"\n",
      "  ],\n",
      "  \"file_type\": \"docx\",\n",
      "  \"character_count\": 5108,\n",
      "  \"word_count\": 716,\n",
      "  \"uploaded_on\": \"2025-06-21 12:07:56\",\n",
      "  \"filename\": \"Finclub Summer Project 2 (2025)[1].docx\",\n",
      "  \"language\": \"en\",\n",
      "  \"named_entities\": [\n",
      "    \"Credit Card Behaviour Score Prediction Using Classification and Risk-Based Techniques\",\n",
      "    \"Bank A\",\n",
      "    \"Summer 2025\",\n",
      "    \"over 30,000\",\n",
      "    \"Behaviour Score\",\n",
      "    \"the following month\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "metadata = generate_metadata(text, os.path.basename(filepath), filetype)\n",
    "print(json.dumps(metadata, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b8970f-3725-4789-9589-6d9e34d6b10c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
