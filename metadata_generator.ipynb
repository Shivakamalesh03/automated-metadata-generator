{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c003463-4457-4ead-b437-981ae3f25866",
   "metadata": {},
   "source": [
    "**Automated Metadata Generator** \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c7831e-f091-40c9-8d2e-782a7aef6617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook demonstrates how to test the metadata generation system locally with PDF, DOCX, and TXT files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac424935-f6a7-4986-9792-82a6d6d0f649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 1.0/12.8 MB 6.2 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 8.9 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 11.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 10.7/12.8 MB 13.3 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 13.2 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install transformers spacy langdetect pdf2image pytesseract python-docx PyMuPDF -q\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd3f67db-c5ef-4fe4-980d-26c797f20f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pytesseract\n",
    "import docx\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from datetime import datetime\n",
    "from transformers import pipeline\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import langdetect\n",
    "import uuid\n",
    "import spacy\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b1292e0-fa0f-4570-83cb-d4a5383e7fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Setup logging and load models\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "try:\n",
    "    summarizer = pipeline(\"summarization\", model=\"t5-small\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to load summarizer: {e}\")\n",
    "    summarizer = None\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to load spaCy model: {e}\")\n",
    "    nlp = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a5db8fe-91f8-494e-be91-a3fff34321f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_txt(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return file.read()\n",
    "\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    text = \"\"\n",
    "    doc = fitz.open(file_path)\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def extract_text_from_scanned_pdf(file_path):\n",
    "    images = convert_from_path(file_path)\n",
    "    text = \"\"\n",
    "    for image in images:\n",
    "        text += pytesseract.image_to_string(image)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "970181c8-c6ed-4321-9374-c653bbd02906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metadata(text, filename, filetype, page_count=None):\n",
    "    words = text.split()\n",
    "    lines = text.strip().split(\"\\n\")\n",
    "\n",
    "    title = next((line.strip() for line in lines if len(line.strip()) > 10), filename)\n",
    "    if len(title) > 80:\n",
    "        title = title[:77] + \"...\"\n",
    "\n",
    "    try:\n",
    "        if summarizer:\n",
    "            summary = summarizer(text[:1000], max_new_tokens=100, do_sample=False)[0]['summary_text']\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Summarizer not available\")\n",
    "    except:\n",
    "        summary = \" \".join(words[:40]) + (\"...\" if len(words) > 40 else \"\")\n",
    "    summary = summary.strip()\n",
    "\n",
    "    cleaned_words = [word.lower().strip(\".,()[]{}\\\":'\") for word in words if len(word) > 4 and word.lower() not in ENGLISH_STOP_WORDS]\n",
    "    freq_keywords = [word for word, count in Counter(cleaned_words).most_common(15)]\n",
    "    keywords = list(dict.fromkeys(freq_keywords))[:10]\n",
    "\n",
    "    try:\n",
    "        language = langdetect.detect(text[:1000])\n",
    "    except:\n",
    "        language = \"unknown\"\n",
    "\n",
    "    if nlp:\n",
    "        doc = nlp(text[:1000])\n",
    "        named_entities = list(set([ent.text for ent in doc.ents if len(ent.text.strip()) > 3]))\n",
    "    else:\n",
    "        named_entities = []\n",
    "\n",
    "    metadata = {\n",
    "        \"document_id\": str(uuid.uuid4()),\n",
    "        \"title\": title,\n",
    "        \"summary\": summary,\n",
    "        \"keywords\": keywords,\n",
    "        \"file_type\": filetype,\n",
    "        \"character_count\": len(text),\n",
    "        \"word_count\": len(words),\n",
    "        \"uploaded_on\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"filename\": filename,\n",
    "        \"language\": language,\n",
    "        \"named_entities\": named_entities\n",
    "    }\n",
    "\n",
    "    if page_count:\n",
    "        metadata[\"page_count\"] = page_count\n",
    "\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61b8970f-3725-4789-9589-6d9e34d6b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace with your file path\n",
    "file_path = r\"C:\\Users\\SHIVA KAMALESH\\Downloads\\Matthew-N.-O.-Sadiku-Elements-of-Electromagnetics-Oxford-University-Press-2018.pdf\"\n",
    "filetype = file_path.split(\".\")[-1].lower()\n",
    "\n",
    "if filetype == \"txt\":\n",
    "    text = extract_text_from_txt(file_path)\n",
    "elif filetype == \"docx\":\n",
    "    text = extract_text_from_docx(file_path)\n",
    "elif filetype == \"pdf\":\n",
    "    try:\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "    except:\n",
    "        text = extract_text_from_scanned_pdf(file_path)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported file type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cdfaea0-d5c3-4087-ad44-9015f24a27ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"document_id\": \"aa826045-92c5-4e0e-9ae3-fd0cdf80ff0c\",\n",
      "  \"title\": \"PRACTICAL APPLICATIONS\",\n",
      "  \"summary\": \"some of the real-life applications covered in this book are listed in order of appearance . applications of electrostatics (Section 4.1) and electrostatic separation of solids (Example 4.3) .\",\n",
      "  \"keywords\": [\n",
      "    \"figure\",\n",
      "    \"field\",\n",
      "    \"charge\",\n",
      "    \"current\",\n",
      "    \"vector\",\n",
      "    \"magnetic\",\n",
      "    \"point\",\n",
      "    \"chapter\",\n",
      "    \"electric\",\n",
      "    \"example\"\n",
      "  ],\n",
      "  \"file_type\": \"pdf\",\n",
      "  \"character_count\": 1275854,\n",
      "  \"word_count\": 245702,\n",
      "  \"uploaded_on\": \"2025-06-24 15:02:10\",\n",
      "  \"filename\": \"Matthew-N.-O.-Sadiku-Elements-of-Electromagnetics-Oxford-University-Press-2018.pdf\",\n",
      "  \"language\": \"en\",\n",
      "  \"named_entities\": [\n",
      "    \"Section 5.9B\",\n",
      "    \"6.52\",\n",
      "    \"Chapter 8\",\n",
      "    \"Section 4.1\",\n",
      "    \"14.6\",\n",
      "    \"Section 7.1\",\n",
      "    \"11.8\",\n",
      "    \"Section 6.5\",\n",
      "    \"Section 7.10\",\n",
      "    \"Section 7.4C\",\n",
      "    \"Section 5.10\",\n",
      "    \"Chapter 12\",\n",
      "    \"Section 4.11\",\n",
      "    \"Section 7.9\",\n",
      "    \"Microstrip\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "metadata = generate_metadata(text, os.path.basename(file_path), filetype)\n",
    "print(json.dumps(metadata, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e04eaa0-fa7b-4d6e-a2bf-68451f3bda56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
